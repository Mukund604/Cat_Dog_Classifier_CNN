{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 399 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Datadir = '/Users/mukund/Documents/GitHub/Cat_Dog_Classifier_CNN/Dataset/PetImages'\n",
    "Categories = os.listdir(Datadir)\n",
    "img_size = 100\n",
    "training_data = []\n",
    "\n",
    "\n",
    "def create_training_data():\n",
    "    for category in Categories:\n",
    "        path = os.path.join(Datadir,category)\n",
    "        class_num = Categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (img_size,img_size))\n",
    "                training_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, labels in training_data:\n",
    "    X.append(features)\n",
    "    y.append(labels)\n",
    "    \n",
    "\n",
    "X = np.array(X).reshape(-1, img_size,img_size, 1) # -1 so that it takes all the features and the last 1 because we are dealing with a gray scale data therefore we have 1 diemnsion, unlike rgb data which would have 3 dimension\n",
    "X = X/255.0\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 107ms/step - accuracy: 0.5582 - loss: 0.7143 - val_accuracy: 0.6577 - val_loss: 0.6152\n",
      "Epoch 2/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 105ms/step - accuracy: 0.6661 - loss: 0.6112 - val_accuracy: 0.7375 - val_loss: 0.5417\n",
      "Epoch 3/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 105ms/step - accuracy: 0.7591 - loss: 0.5017 - val_accuracy: 0.7752 - val_loss: 0.4788\n",
      "Epoch 4/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 107ms/step - accuracy: 0.7923 - loss: 0.4470 - val_accuracy: 0.7876 - val_loss: 0.4585\n",
      "Epoch 5/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 113ms/step - accuracy: 0.8139 - loss: 0.4057 - val_accuracy: 0.7848 - val_loss: 0.4661\n",
      "Epoch 6/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 107ms/step - accuracy: 0.8362 - loss: 0.3665 - val_accuracy: 0.7888 - val_loss: 0.4591\n",
      "Epoch 7/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 107ms/step - accuracy: 0.8641 - loss: 0.3190 - val_accuracy: 0.7948 - val_loss: 0.4707\n",
      "Epoch 8/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 107ms/step - accuracy: 0.8747 - loss: 0.2910 - val_accuracy: 0.7916 - val_loss: 0.4897\n",
      "Epoch 9/10\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 108ms/step - accuracy: 0.8912 - loss: 0.2587 - val_accuracy: 0.7880 - val_loss: 0.5569\n",
      "Epoch 10/10\n",
      "\u001b[1m225/702\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 105ms/step - accuracy: 0.9160 - loss: 0.2113"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "print(type(X))\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64,(3,3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "\n",
    "#Need to add flatten as Conv2d takes 2d arguement, but dense layer takes 1d\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X,y, batch_size = 32, epochs = 5, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
